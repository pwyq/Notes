\documentclass[lang=en,mode=geye,device=normal,color=blue,14pt]{elegantnote}
\usepackage{amsmath,amssymb}
\usepackage{bbm}
\usepackage{tcolorbox}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{subfiles}
\usepackage{pythonhighlight}

\usepackage{xcolor}
\definecolor{shadecolor}{RGB}{150,150,150}
\newcommand{\mybox}[1]{\par\noindent\colorbox{shadecolor}
{\parbox{\dimexpr\textwidth-2\fboxsep\relax}{#1}}}

\DeclareMathOperator*{\E}{\mathbb{E}}
\DeclareMathOperator*{\1}{\mathbbm{1}}
\DeclareMathOperator*{\R}{\mathbbm{R}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Note: Reinforcement Learning - An Introduction}

%\author{Yanqing Wu}
%\institute{Viwistar Robotics}

% \version{0.1.0}
%\date{\today}

\begin{document}
\maketitle

\setlength{\parindent}{0pt}

%%%%%%%%%%%%%%%%%%%%%%%

\subfile{chapter_1.tex}

%%%%%%%%%%%%%%%%%%%%%%%

\subfile{chapter_2.tex}

%%%%%%%%%%%%%%%%%%%%%%%

\subfile{chapter_3.tex}

%%%%%%%%%%%%%%%%%%%%%%%

\subfile{chapter_4.tex}

%%%%%%%%%%%%%%%%%%%%%%%


\newpage
\section{Monte Carlo Methods}

\subsection{Learning Objectives (UA RL MOOC)}

Lesson 1: Introduction to Monte-Carlo Methods 

Understand how Monte-Carlo methods can be used to estimate value functions from sampled interaction 

Identify problems that can be solved using Monte-Carlo methods 

Use Monte-Carlo prediction to estimate the value function for a given policy. 

Lesson 2: Monte-Carlo for Control 

Estimate action-value functions using Monte-Carlo 

Understand the importance of maintaining exploration in Monte-Carlo algorithms 

Understand how to use Monte-Carlo methods to implement a GPI algorithm

Apply Monte-Carlo with exploring starts to solve an MDP 

Lesson 3: Exploration Methods for Monte-Carlo 

Understand why exploring starts can be problematic in real problems 

Describe an alternative exploration method for Monte-Carlo control 

Lesson 4: Off-policy learning for prediction 

Understand how off-policy learning can help deal with the exploration problem 

Produce examples of target policies and examples of behavior policies

Understand importance sampling 

Use importance sampling to estimate the expected value of a target distribution using samples from a different distribution

Understand how to use importance sampling to correct returns 

Understand how to modify the Monte-Carlo prediction algorithm for off-policy learning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subfile{chapter_extra_notes.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{references.bib}

\end{document}